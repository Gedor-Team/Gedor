{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27480 entries, 0 to 27479\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  27479 non-null  object\n",
      " 1   category   27480 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 429.5+ KB\n"
     ]
    }
   ],
   "source": [
    "x_data = pd.read_csv('datax.csv')\n",
    "x_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669 entries, 0 to 668\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  669 non-null    object\n",
      " 1   category   669 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "review_data = pd.read_csv('../complaints.csv')\n",
    "review_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = review_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = review_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 642 entries, 0 to 656\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  642 non-null    object\n",
      " 1   category   642 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.0+ KB\n"
     ]
    }
   ],
   "source": [
    "review_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thori\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complaint(complaint):\n",
    "    # Remove usernames after '@'\n",
    "    complaint = re.sub(r'@\\w+', '', complaint)\n",
    "    # Remove URLs\n",
    "    complaint = re.sub(r'http\\S+', '', complaint)\n",
    "    # Remove punctuation and special symbols (commas, periods, etc.)\n",
    "    complaint = re.sub(r'[^\\w\\s]', '', complaint)\n",
    "    # Remove leading whitespace (if any)\n",
    "    complaint = complaint.lstrip()\n",
    "    # Remove extra whitespace\n",
    "    complaint = re.sub(r'\\s+', ' ', complaint).strip()\n",
    "    return complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['complaint'] = x_data['complaint'].apply(clean_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'di sisi lain istriku selalu seneng lihat hujan karena pas kecil pernah ngalamin kekeringan parah yg ampe air aja dijatah dan harus ngantri kalo musim hujannya mundur suka gak tenang karena keinget'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['complaint'] = review_data['complaint'].apply(clean_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as of 23 april 2019 di gedung utamanya dari dulu terkenal sbg tempat perkawinan bergengsi di foto terlampir adalah kegiatan kordinasi nasional khusus nya antara esdm dan dishut dalam upaya revegetasi hutan dan das akibat tambang bagus lah'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"indonesian\"))\n",
    "stemmer = PorterStemmer()\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(complaint):\n",
    "     # Tokenize the text\n",
    "    tokens = word_tokenize(complaint)\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    cleaned_tokens = [stemmer.stem(word) for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join the translated tokens back into a single string\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['complaint'] = x_data['complaint'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['complaint'] = review_data['complaint'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ava kpop pemuja cwo ngondek melambai denial kalo jefri nichol ga ganteng kebanyakan kena limbah plasti mata lu the one beauti priveleg is real manusia pemikirannya fluktuatif berubah ubah ditambah muda'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.iloc[26695,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames\n",
    "merged_data = pd.concat([x_data, review_data], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_data.to_csv('merged_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
