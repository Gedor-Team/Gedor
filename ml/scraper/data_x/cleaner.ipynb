{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27480 entries, 0 to 27479\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  27479 non-null  object\n",
      " 1   category   27480 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 429.5+ KB\n"
     ]
    }
   ],
   "source": [
    "x_data = pd.read_csv('datax.csv')\n",
    "x_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669 entries, 0 to 668\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  669 non-null    object\n",
      " 1   category   669 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "review_data = pd.read_csv('../complaints.csv')\n",
    "review_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = review_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = review_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 642 entries, 0 to 656\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   complaint  642 non-null    object\n",
      " 1   category   642 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.0+ KB\n"
     ]
    }
   ],
   "source": [
    "review_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thori\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complaint(complaint):\n",
    "    # Remove usernames after '@'\n",
    "    complaint = re.sub(r'@\\w+', '', complaint)\n",
    "    # Remove URLs\n",
    "    complaint = re.sub(r'http\\S+', '', complaint)\n",
    "    # Remove punctuation and special symbols (commas, periods, etc.)\n",
    "    complaint = re.sub(r'[^\\w\\s]', '', complaint)\n",
    "    # Remove extra whitespace\n",
    "    complaint = re.sub(r'\\s+', ' ', complaint).strip()\n",
    "    # Remove any zero-width characters like 'ã…¤'\n",
    "    complaint = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u3164]+', '', complaint)\n",
    "    return complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['complaint'] = x_data['complaint'].apply(clean_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'di sisi lain istriku selalu seneng lihat hujan karena pas kecil pernah ngalamin kekeringan parah yg ampe air aja dijatah dan harus ngantri kalo musim hujannya mundur suka gak tenang karena keinget'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['complaint'] = review_data['complaint'].apply(clean_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as of 23 april 2019 di gedung utamanya dari dulu terkenal sbg tempat perkawinan bergengsi di foto terlampir adalah kegiatan kordinasi nasional khusus nya antara esdm dan dishut dalam upaya revegetasi hutan dan das akibat tambang bagus lah'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"indonesian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "lemmatizer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(complaint):\n",
    "    complaint = complaint.lower()\n",
    "     #Tokenize and remove stop words\n",
    "    words = [word for word in complaint.split() if word not in stop_words]\n",
    "    # Apply lemmatization\n",
    "    lemmatized_words = [lemmatizer.stem(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['complaint'] = x_data['complaint'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data['complaint'] = review_data['complaint'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames\n",
    "merged_data = pd.concat([x_data, review_data], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_data.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.loc[(merged_data['category'] == 'jalan rusak')|(merged_data['category'] == 'macet'), 'category'] = 'fasilitas umum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.loc[(merged_data['category'] == 'others'), 'category'] = 'lainnya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.loc[(merged_data['category'] == 'tercemar')|(merged_data['category'] == 'pencemaran')|(merged_data['category'] == 'asap')|(merged_data['category'] == 'air'), 'category'] = 'polusi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex pattern to keep rows that contain mainly alphabetic characters and spaces\n",
    "pattern = r'^[a-zA-Z\\s]+$'\n",
    "\n",
    "# Filter out rows that don't match this pattern\n",
    "merged_data = merged_data[merged_data['complaint'].str.match(pattern, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords that identify 'layanan' complaints\n",
    "keywords = ['pungli', 'service', 'biaya', 'dokumen', 'izin', 'servis', 'pelayanan', 'layanan', 'dibenahi', 'dibereskan', 'perhatikan', 'server', 'lapor', 'laporan']  \n",
    "\n",
    "# Update 'category' if 'lainnya' contains any keywords\n",
    "merged_data.loc[\n",
    "    (merged_data['category'] == 'lainnya') & \n",
    "    (merged_data['complaint'].str.contains('|'.join(keywords), case=False)),\n",
    "    'category'\n",
    "] = 'layanan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data[~(merged_data['complaint'].str.len() < 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords that identify 'lingkungan' complaints\n",
    "keywords = ['banjir', 'kemarau', 'hujan', 'angin', 'tanah', 'kebakaran']  \n",
    "\n",
    "# Update 'category' if 'lainnya' contains any keywords\n",
    "merged_data.loc[\n",
    "    (merged_data['category'] == 'lainnya') & \n",
    "    (merged_data['complaint'].str.contains('|'.join(keywords), case=False)),\n",
    "    'category'\n",
    "] = 'lingkungan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords that identify 'kekeringan' complaints\n",
    "keywords = ['kering', 'tandus', 'gersang']  \n",
    "\n",
    "# Update 'category' if 'lainnya' contains any keywords\n",
    "merged_data.loc[\n",
    "    (merged_data['category'] == 'lainnya') & \n",
    "    (merged_data['complaint'].str.contains('|'.join(keywords), case=False)),\n",
    "    'category'\n",
    "] = 'lingkungan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords that identify 'sampah' complaints\n",
    "keywords = ['tpa', 'plastik']  \n",
    "\n",
    "# Update 'category' if 'lainnya' contains any keywords\n",
    "merged_data.loc[\n",
    "    (merged_data['category'] == 'lainnya') & \n",
    "    (merged_data['complaint'].str.contains('|'.join(keywords), case=False)),\n",
    "    'category'\n",
    "] = 'sampah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polusi</td>\n",
       "      <td>3190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lingkungan</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasilitas umum</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lainnya</td>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sampah</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hutan</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limbah</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layanan</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kekeringan</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category  count\n",
       "0          polusi   3190\n",
       "1      lingkungan   2692\n",
       "2  fasilitas umum   2474\n",
       "3         lainnya   2206\n",
       "4          sampah   1574\n",
       "5           hutan   1129\n",
       "6          limbah    295\n",
       "7         layanan    136\n",
       "8      kekeringan     94"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['category'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['prabowo', 'jokowi', 'gibran', 'wowo', 'owi', 'pramono', 'ronald tanur', 'ivan', 'anies', 'anis', 'ahok', 'gerindra', 'greenflag', 'leceh'\n",
    "           ,'pedo', 'baju', 'masak', 'kebahagiaan', 'penipuan', 'love', 'cinta', 'lgbt', 'stylish', 'harga', 'densu', 'kpop', 'wibu', 'mental',\n",
    "           'extrovert', 'introvert', 'fitnah', 'semangka', 'paul', 'post', 'edit', 'napi', 'blow', 'lagu', 'liga', 'baper', 'fess', 'base'\n",
    "           ,'psi', 'kartika', 'nasi', 'pecel']\n",
    "merged_data = merged_data[~merged_data['complaint'].str.contains('|'.join(keywords), case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 rows from merged_data\n",
    "train_data = merged_data.sample(n=1000, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_complaint'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['complaint','is_complaint']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('../spam_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polusi</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lingkungan</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasilitas umum</td>\n",
       "      <td>2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lainnya</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sampah</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hutan</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limbah</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layanan</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kekeringan</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category  count\n",
       "0          polusi   2770\n",
       "1      lingkungan   2352\n",
       "2  fasilitas umum   2229\n",
       "3         lainnya   1954\n",
       "4          sampah   1379\n",
       "5           hutan   1032\n",
       "6          limbah    267\n",
       "7         layanan    122\n",
       "8      kekeringan     88"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['category'].value_counts().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
